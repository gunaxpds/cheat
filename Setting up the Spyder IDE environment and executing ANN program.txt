Classification:
#Importing the necessary libraries
import pandas as pd
import numpy as np
from sklearn.datasets import make_classification, make_regression
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
import sklearn
dir(sklearn.datasets)
#importing the dataset
data = make_classification(200,4,random_state=1)
data
x = data[0]
y = data[1]
#Model Creation
model = Sequential()
model.add(Dense(1135, activation='tanh', input_dim=4))
model.add(Dense(624, activation='relu'))
model.add(Dense(114, activation='relu'))
model.add(Dense(1,activation='sigmoid'))
adam = Adam(0.001)
#model compilation
model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])
print(model.summary())
history = model.fit(x, y, epochs=150, batch_size=5, validation_split=0.2)
pd.DataFrame(model.history.history).reset_index().plot('index', kind='line')
data = pd.DataFrame(history.history)
data.loc[data['accuracy'].idxmax()]
Regression:
#importing the dataset
data = make_regression(200,4,random_state=1)
x=data[0]
y=data[1]
#r2
from keras import backend as k
def r2(y_true,y_pred):
 ss_res = k.sum(k.square(y_true-y_pred))
 ss_tot = k.sum(k.square(y_true-k.mean(y_true)))
 return (1-ss_res/(ss_tot))
#Model Creation
model = Sequential()
model.add(Dense(1135,activation= 'tanh', input_dim = 4))
model.add(Dense(624, activation='relu'))
model.add(Dense(114))
model.add(Dense(1))
adam = Adam(0.0001)
#Model compilation
model.compile(optimizer=adam, loss='mean_squared_error', metrics=[r2])
print(model.summary())
history = model.fit(x,y,epochs=150, batch_size=5, validation_split=0.2)
pd.DataFrame(model.history.history)[['r2','val_r2']].reset_index().plot('index', kind='line')
data = pd.DataFrame(history.history)
data.loc[data['r2'].idxmax()]

